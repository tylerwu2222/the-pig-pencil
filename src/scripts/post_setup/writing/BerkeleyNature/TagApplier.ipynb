{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# import cv2\n",
    "import requests\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "import pandas as pd\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "import re\n",
    "data_folder = '../../../src/components/BlogPosts/BerkeleyNature/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = '../../../src/components/BlogPosts/BerkeleyNature/Images'\n",
    "absolute_path = r\"C:\\Users\\tyler\\PersonalProjects\\small-data-blog\\src\\components\\BlogPosts\\BerkeleyNature\\Images\"\n",
    "images = os.listdir(images_folder)\n",
    "extensions = ['.jpg','.JPG']\n",
    "images = [os.path.join(absolute_path,i) for i in images if any(ext in i for ext in extensions)]\n",
    "images[:1]\n",
    "# 'src\\components\\BlogPosts\\BerkeleyNature\\Images'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort images by date (oldest --> newest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_date_dict = {}\n",
    "r = re.compile('202.*')\n",
    "for img in images:\n",
    "    img_name = img.split('\\\\')[-1]\n",
    "    # print(img_name)\n",
    "    image = Image.open(img)\n",
    "    exifdata = image.getexif()\n",
    "    tag_values = [e for e in list(exifdata.values()) if isinstance(e, str)]\n",
    "    if len(tag_values) == 0:\n",
    "        image_date_dict[img_name] = None\n",
    "    # print(tag_values)\n",
    "    else:\n",
    "        try:\n",
    "            date = list(filter(r.match, tag_values))[0]\n",
    "        except:\n",
    "            print(img_name,date)\n",
    "            date = '2022/12/14'\n",
    "        date = date.split(' ')[0].replace(':','/')\n",
    "        # print(date)\n",
    "        image_date_dict[img_name] = date\n",
    "image_date_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_date_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort images by value (date), moving null dates to end\n",
    "sorted_images_dict = {k: v for k, v in sorted(image_date_dict.items(), key=lambda x: (x[1] is None, x[1]))}\n",
    "len(sorted_images_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null dates\n",
    "sorted_images_no_null = [k for k,v in sorted_images_dict.items() if v is not None]\n",
    "print(len(sorted_images_no_null))\n",
    "sorted_images = sorted_images_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW : get image tags via API\n",
    "API_ENDPOINT = \"https://imagerecognize.com/api/v3/\"\n",
    "f = open('../api_keys.json')\n",
    "key = json.load(f)\n",
    "API_KEY = key[\"ImageRecognize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_ordered_images = pd.read_csv(data_folder + '/image_metadata.csv').loc[:,'img']\n",
    "excel_ordered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_image_size(image):\n",
    "    load_image = Image.open(os.path.join(images_folder,image))\n",
    "    load_image = load_image.resize((int(load_image.size[0]/2),int(load_image.size[1]/2)),Image.ANTIALIAS)\n",
    "    load_image.save(os.path.join(images_folder,'small_folder','smaller_'+image), optimize=True, quality=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 124\n",
    "image_json = {}\n",
    "\n",
    "headers = {'Accept': 'application/json'}\n",
    "\n",
    "for i, image in enumerate(excel_ordered_images[offset:]):\n",
    "    time.sleep(1)\n",
    "    print(i,'/',len(excel_ordered_images) - offset,image)\n",
    "    if i % 5 == 0:\n",
    "        \n",
    "        print('json:',image_json)\n",
    "    with open(os.path.join(images_folder,image) , 'rb') as f:\n",
    "        f = {'file': f.read()}\n",
    "\n",
    "    d = {'apikey': API_KEY,\n",
    "        'type': 'objects',\n",
    "        'max_labels': 10,\n",
    "        'min_confidence': 80}\n",
    "\n",
    "    r = requests.post(url=API_ENDPOINT, data=d, files=f,headers=headers)\n",
    "    if type(r) == requests.models.Response:\n",
    "        print('type class')\n",
    "        if str(r) =='<Response [403]>':\n",
    "            print('error 413')\n",
    "            # if image too large, save as smaller size and retest\n",
    "            reduce_image_size(image)\n",
    "            with open(os.path.join(images_folder,'small_folder','smaller_'+image) , 'rb') as f:\n",
    "                f = {'file': f.read()}\n",
    "            r = requests.post(url=API_ENDPOINT, data=d, files=f)\n",
    "            result = json.loads(r.text)\n",
    "            image_json[image] = result.get('data')\n",
    "            continue\n",
    "        else:\n",
    "            result = json.loads(r.text)\n",
    "            image_json[image] = result.get('data')\n",
    "            continue\n",
    "\n",
    "    else:\n",
    "        print('other type',type(r))\n",
    "        if result['status'] == 200:\n",
    "            image_json[image] = result.get('data')\n",
    "        elif result['status'] == 413:\n",
    "            print('error 413')\n",
    "            # if image too large, save as smaller size and retest\n",
    "            reduce_image_size(image)\n",
    "            with open(os.path.join(images_folder,'smaller_',image) , 'rb') as f:\n",
    "                f = {'file': f.read()}\n",
    "            r = requests.post(url=API_ENDPOINT, data=d, files=f)\n",
    "            result = json.loads(r.text)\n",
    "            image_json[image] = result.get('data')\n",
    "            continue\n",
    "        else:\n",
    "            print(offset + i, image,'error:',result)\n",
    "image_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_json)\n",
    "# i\n",
    "# Image size too large\n",
    "# sub_list = [i for i in excel_ordered_images[:124] if i not in ['marina (4).jpg','tree (2).jpg']]\n",
    "# len(sub_list)\n",
    "# img_dict = dict(zip(sub_list,image_json))\n",
    "# img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + '/image_tags1.json', 'w') as outfile:\n",
    "    json.dump(image_json, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marina (4).jpg not found\n",
      "tree (2).jpg not found\n"
     ]
    }
   ],
   "source": [
    "# combine data\n",
    "f0 = open(data_folder + '/image_tags0.json', 'r')\n",
    "data0 = json.load(f0)\n",
    "\n",
    "f1 = open(data_folder + '/image_metadata.json', 'r')\n",
    "data1 = json.load(f1)\n",
    "\n",
    "for d in data1:\n",
    "    # print(d)\n",
    "    try:\n",
    "        d['tags'] = [o['name'] for o in data0.get(d.get('img')).get('objects')]\n",
    "    except:\n",
    "        print(d['img'], 'not found')\n",
    "        d['tags'] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['marina (4).jpg','tree (2).jpg']:\n",
    "    reduce_image_size(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + '/image_data_complete.json', 'w') as outfile:\n",
    "    json.dump(data1, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD: get image tags via scraping \n",
    "driver = webdriver.Edge(service=Service(EdgeChromiumDriverManager().install()))\n",
    "\n",
    "rec_url = 'https://imagerecognize.com/'\n",
    "driver.maximize_window()\n",
    "driver.get(rec_url)\n",
    "\n",
    "short_wait_time = 3\n",
    "loading_wait_time = 30\n",
    "offset = 6\n",
    "image_tags_dict = {}\n",
    "for i, image in enumerate(sorted_images[offset:]):\n",
    "    print(image,'({0}/{1})'.format(i,len(sorted_images[offset:])))\n",
    "    full_image = os.path.join(absolute_path,image)\n",
    "    file_drop = driver.find_element(By.ID,\"drop_file_zone\")\n",
    "    try:\n",
    "        file_drop.click()\n",
    "    except ElementClickInterceptedException as e:\n",
    "        print('click intercepted, but fuck it we ball')\n",
    "        file_drop.click()\n",
    "    time.sleep(1)\n",
    "    # upload image and enter\n",
    "    pyautogui.write(full_image)\n",
    "    pyautogui.press('enter')\n",
    "    # wait for loading then wait for results to populate\n",
    "    try:\n",
    "        WebDriverWait(driver, short_wait_time).until(EC.presence_of_element_located((By.ID,'loading')))\n",
    "        print('started loading...')\n",
    "    except:\n",
    "        print('incorrect file type?')\n",
    "        continue\n",
    "    try:\n",
    "        WebDriverWait(driver, loading_wait_time).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"response\"]/h3[1]')))\n",
    "    except:\n",
    "        print('image too big?')\n",
    "        continue\n",
    "    response = driver.find_element(By.ID,'response')\n",
    "    # '//*[@id=\"respoC:\\Users\\tyler\\PersonalProjects\\small-data-blog\\src\\components\\BlogPosts\\BerkeleyNature\\Images\\animal (8).jpg\n",
    "    # nse\"]/h3[1]'\n",
    "    children = response.find_elements(By.XPATH,'./h3')\n",
    "    tags = [c.text.split(' ')[0] for c in children]\n",
    "    # print(children)\n",
    "    # save tags in dataframe\n",
    "    image_tags_dict[image] = tags\n",
    "image_tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.DataFrame(columns=['img','tags'],data=image_tags_dict.items())\n",
    "tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df['date'] = tag_df['img'].map(image_date_dict)\n",
    "tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_images_df = pd.DataFrame(sorted_images)\n",
    "sorted_images_df.to_csv(os.path.join(data_folder,'sorted_images.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to excel file for metadata\n",
    "tag_df.to_csv(os.path.join(data_folder,'image_metadata_copy.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add date to metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0420d7d8aef4f0cc439acea0c78cc7786074a26bb4830ab7d5d8dcbb2e116359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
