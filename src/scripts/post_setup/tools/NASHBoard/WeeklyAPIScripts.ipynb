{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData\n",
    "# import sqlite3\n",
    "import http.client\n",
    "import time\n",
    "import collections\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../../components/Tools/NASHBoard/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../api_keys.json')\n",
    "data = json.load(f)\n",
    "API_key = data[\"SportRadar\"]\n",
    "\n",
    "# establish connection to API\n",
    "conn = ''\n",
    "def get_conn():\n",
    "    global conn \n",
    "    conn = http.client.HTTPSConnection(\"api.sportradar.us\")\n",
    "get_conn()\n",
    "\n",
    "# function to get and minimally format data given url\n",
    "def get_data(url):\n",
    "    conn.request(\"GET\", url)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    return json.loads(data.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET INJURY DATA\n",
    "injury_data = get_data(\"/nba/trial/v7/en/league/injuries.json?api_key=%s\" %API_key)\n",
    "# reformat injuries data\n",
    "injuries_list = []\n",
    "\n",
    "for i, row in enumerate(injury_data['teams']):\n",
    "    team = row['market'] + ' ' + row['name']\n",
    "    for player in row['players']:\n",
    "        injured = {}\n",
    "        injured['id'] = i\n",
    "        injured['team_name'] = team\n",
    "        injured.update({k: player[k] for k in ('full_name', 'primary_position','reference')})\n",
    "        injured.update({k: player['injuries'][0][k] for k in ('comment', 'status','start_date','update_date')})\n",
    "        injured['player_id'] = injured.pop('reference')\n",
    "        injuries_list.append(injured)\n",
    "\n",
    "# store in json\n",
    "with open(data_folder + 'injuries.json', 'w') as outfile:\n",
    "    json.dump(injuries_list, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 of 1230\n",
      "game 100 of 1230\n",
      "game 200 of 1230\n",
      "game 300 of 1230\n",
      "game 400 of 1230\n",
      "game 500 of 1230\n",
      "game 600 of 1230\n",
      "game 700 of 1230\n",
      "game 800 of 1230\n",
      "game 900 of 1230\n",
      "game 1000 of 1230\n",
      "game 1100 of 1230\n",
      "game 1200 of 1230\n"
     ]
    }
   ],
   "source": [
    "# UPDATE WEEKLY GAMES\n",
    "season = \"2022\"\n",
    "get_conn()\n",
    "curr_season_schedule = get_data(\"/nba/trial/v7/en/games/\" + season + \"/REG/schedule.json?api_key=%s\" %API_key)\n",
    "games_list = []\n",
    "future_games_list = []\n",
    "num_games = len(curr_season_schedule['games'])\n",
    "for i, row in enumerate(curr_season_schedule['games']):\n",
    "    if i % 100 == 0:\n",
    "        print('game',i,'of',num_games)\n",
    "        \n",
    "    game = {}\n",
    "    if row['status'] == 'postponed' or row['status'] == 'cancelled':\n",
    "        continue\n",
    "    else:\n",
    "        game['time_zone'] = row['time_zones']['venue']\n",
    "        game['network'] = row['broadcasts'][0]['network'] if row.get('broadcasts') else 'missing'\n",
    "        try:\n",
    "            game['locale'] = row['broadcasts'][0]['locale']\n",
    "        except:\n",
    "            game['locale'] = 'home'\n",
    "        game['home'] = row['home']['name']\n",
    "        game['away'] = row['away']['name']\n",
    "        # add to future games list if not yet played\n",
    "        if row['status'] == 'scheduled':\n",
    "            game.update({k: row[k] for k in ('id', 'scheduled')})\n",
    "            future_games_list.append(game)\n",
    "        # else, add to played games list\n",
    "        else:\n",
    "            # try:\n",
    "            # game.update({k: row[k] for k in ('id', 'scheduled','home_points','away_points')})\n",
    "            game.update({k: row[k] for k in ('id', 'scheduled')})\n",
    "            games_list.append(game)\n",
    "    \n",
    "# add to current year schedule jsons\n",
    "with open(data_folder + 'season_' + season + '_schedule.json', 'w') as outfile:\n",
    "    json.dump(games_list, outfile)\n",
    "with open(data_folder + 'season_' + season + '_remaining_schedule.json', 'w') as outfile:\n",
    "    json.dump(future_games_list, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roster json\n",
    "with open(data_folder + 'teams.json', \"r\") as read_content:\n",
    "    team_json = json.load(read_content)\n",
    "team_ids = {t['teamName']:t['sr-id'] for t in team_json}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlanta Hawks\n",
      "Boston Celtics\n",
      "Brooklyn Nets\n",
      "Charlotte Hornets\n",
      "Chicago Bulls\n",
      "Cleveland Cavaliers\n",
      "Dallas Mavericks\n",
      "Denver Nuggets\n",
      "Detroit Pistons\n",
      "Golden State Warriors\n",
      "Houston Rockets\n",
      "Indiana Pacers\n",
      "LA Clippers\n",
      "Los Angeles Lakers\n",
      "Memphis Grizzlies\n",
      "Miami Heat\n",
      "Milwaukee Bucks\n",
      "Minnesota Timberwolves\n",
      "New Orleans Pelicans\n",
      "New York Knicks\n",
      "Oklahoma City Thunder\n",
      "Orlando Magic\n",
      "Philadelphia 76ers\n",
      "Phoenix Suns\n",
      "Portland Trail Blazers\n",
      "Sacramento Kings\n",
      "San Antonio Spurs\n",
      "Toronto Raptors\n",
      "Utah Jazz\n",
      "Washington Wizards\n"
     ]
    }
   ],
   "source": [
    "# GET UPDATED TEAM SPLITS\n",
    "year = '2022'\n",
    "get_conn()\n",
    "team_splits = {}\n",
    "split_splits = [0,4,10]\n",
    "\n",
    "for t,i in team_ids.items():\n",
    "    print(t)\n",
    "    time.sleep(1)\n",
    "    data = get_data(\"/nba/trial/v7/en/seasons/\" + year + \"/REG/teams/\" + i + \"/splits/ingame.json?api_key=%s\"%API_key)\n",
    "    total_games = 0\n",
    "    weighted_opp_splits_list = []\n",
    "    weighted_self_splits_list = []\n",
    "    for s in split_splits:\n",
    "        split_games = data['splits'][s]['opponents']['total']['games_played']\n",
    "        total_games = total_games + split_games\n",
    "        opp_splits = data['splits'][s]['opponents']['average']\n",
    "        weighted_opp_splits = {s:opp_splits[s] * split_games for s in list(opp_splits.keys())}\n",
    "        weighted_opp_splits_list.append(weighted_opp_splits)\n",
    "\n",
    "        self_splits = data['splits'][s]['own_record']['average']\n",
    "        weighted_self_splits = {s:self_splits[s] * split_games for s in list(self_splits.keys())}\n",
    "        weighted_self_splits_list.append(weighted_self_splits)\n",
    "\n",
    "    list_keys = [k for k in list(weighted_opp_splits.keys())]\n",
    "    total_weighted_opp_splits = dict(zip(list_keys,[0] * len(list_keys)))\n",
    "    for w in weighted_opp_splits_list:\n",
    "        for k in list_keys:\n",
    "            total_weighted_opp_splits[k] += w[k]\n",
    "    total_weighted_opp_splits = {k:round(i/total_games,2) for k,i in total_weighted_opp_splits.items()}\n",
    "\n",
    "    total_weighted_self_splits = dict(zip(list_keys,[0] * len(list_keys)))\n",
    "    for w in weighted_self_splits_list:\n",
    "        for k in list_keys:\n",
    "            total_weighted_self_splits[k] += w[k]\n",
    "    total_weighted_self_splits = {k:round(i/total_games,2) for k,i in total_weighted_self_splits.items()}\n",
    "\n",
    "    all_splits_dict = {'opponent':total_weighted_opp_splits,'self':total_weighted_self_splits}\n",
    "    team_splits[t] = all_splits_dict\n",
    "# team_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + 'team_splits.json', 'w') as outfile:\n",
    "    json.dump(team_splits, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get player ids from players json\n",
    "with open(data_folder + 'players.json', \"r\") as read_content:\n",
    "    players_json = json.load(read_content)\n",
    "# players_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET CURRENT PLAYER SPLITS\n",
    "\n",
    "# LIST OF PLAYERS WITH TOP 200 Fantasy Score --> only get those...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Justin Holiday of 501\n",
      "25 Derrick White of 501\n",
      "50 Kai Jones of 501\n",
      "75 Malcolm Hill of 501\n",
      "100 Tim Hardaway Jr. of 501\n",
      "125 Bones Hyland of 501\n",
      "150 Patrick Baldwin Jr. of 501\n",
      "175 Josh Christopher of 501\n",
      "200 Ivica Zubac of 501\n",
      "225 Cole Swider of 501\n",
      "250 Bam Adebayo of 501\n",
      "275 Wesley Matthews of 501\n",
      "300 Dereon Seabron of 501\n",
      "325 Svi Mykhailiuk of 501\n",
      "350 Chet Holmgren of 501\n",
      "375 Matisse Thybulle of 501\n",
      "400 Greg Brown III of 501\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tyler\\PersonalProjects\\small-data-blog\\src\\scripts\\NASHBoard\\WeeklyAPIScripts.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/PersonalProjects/small-data-blog/src/scripts/NASHBoard/WeeklyAPIScripts.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m data \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mread()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/PersonalProjects/small-data-blog/src/scripts/NASHBoard/WeeklyAPIScripts.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m player \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tyler/PersonalProjects/small-data-blog/src/scripts/NASHBoard/WeeklyAPIScripts.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m player \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(player)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/PersonalProjects/small-data-blog/src/scripts/NASHBoard/WeeklyAPIScripts.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m season_stats \u001b[39m=\u001b[39m player[\u001b[39m'\u001b[39m\u001b[39mseasons\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tyler/PersonalProjects/small-data-blog/src/scripts/NASHBoard/WeeklyAPIScripts.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m player_dict \u001b[39m=\u001b[39m {s[\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m]: {\u001b[39m'\u001b[39m\u001b[39mteam\u001b[39m\u001b[39m'\u001b[39m:s[\u001b[39m'\u001b[39m\u001b[39mteams\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmarket\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m s[\u001b[39m'\u001b[39m\u001b[39mteams\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m:s[\u001b[39m'\u001b[39m\u001b[39mteams\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtotal\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m'\u001b[39m\u001b[39maverage\u001b[39m\u001b[39m'\u001b[39m:s[\u001b[39m'\u001b[39m\u001b[39mteams\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39maverage\u001b[39m\u001b[39m'\u001b[39m] } \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m season_stats}\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\tyler\\anaconda3\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# GET UPDATED PLAYER SPLITS\n",
    "num_players = len(players_json)\n",
    "get_conn()\n",
    "i = 0\n",
    "players_splits = {}\n",
    "for p_name, p_id in players_json.items():\n",
    "    time.sleep(1)\n",
    "    # if i > 1:\n",
    "    #     break\n",
    "    if i % 25 == 0:\n",
    "        print(i, p_name, 'of',num_players)\n",
    "    conn.request(\"GET\",\"/nba/trial/v7/en/players/\"+p_id+\"/profile.json?api_key=%s\"%API_key)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    player = data.decode(\"utf-8\")\n",
    "    player = json.loads(player)\n",
    "    season_stats = player['seasons']\n",
    "    player_dict = {s['year']: {'team':s['teams'][0]['market'] +' ' + s['teams'][0]['name'], 'total':s['teams'][0]['total'],'average':s['teams'][0]['average'] } for s in season_stats}\n",
    "    players_splits[p_name] = player_dict\n",
    "    i = i + 1\n",
    "players_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_folder + 'player_splitsA.json', 'w') as outfile:\n",
    "    json.dump(players_splits, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE PLAYER BOX SCORES?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0420d7d8aef4f0cc439acea0c78cc7786074a26bb4830ab7d5d8dcbb2e116359"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
